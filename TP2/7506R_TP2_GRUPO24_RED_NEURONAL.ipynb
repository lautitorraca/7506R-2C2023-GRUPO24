{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0hRVe4OJGDv4"
      ],
      "mount_file_id": "1xiva6CTgjO6mXlLwBIV9CoOwMHXY2mkK",
      "authorship_tag": "ABX9TyP4GT5b5WrjN9OsuNl5d68M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lautitorraca/7506R-2C2023-GRUPO24/blob/main/TP2/7506R_TP2_GRUPO24_RED_NEURONAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ùîæùï£ùï¶ùï°ùï† ùüöùüú (Merequetengueüëç)\n",
        "\n",
        "‚û¢ Torraca Lautaro - 108813\n",
        "\n",
        "‚û¢ Negrotti Gianluca - 108184\n",
        "\n",
        "‚û¢ Marco Tosi - 107237"
      ],
      "metadata": {
        "id": "n8kHAUXWFVG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### > Imports"
      ],
      "metadata": {
        "id": "wub9oeo8F--R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Optimizaci√≥n de hiperpar√°metros\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, RepeatedKFold\n",
        "\n",
        "# Manejo de modelos\n",
        "from pickle import dump\n",
        "from pickle import load"
      ],
      "metadata": {
        "id": "apRGqdQ25_-F"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### > Lectura de los datasets"
      ],
      "metadata": {
        "id": "5wxqoxXTGA_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_train = '/content/drive/MyDrive/Colab Notebooks/train_limpio.csv'\n",
        "url_test = '/content/test_limpio.csv'\n",
        "\n",
        "df_train = pd.read_csv(url_train)\n",
        "df_test = pd.read_csv(url_test)\n",
        "\n",
        "train = df_train.copy()\n",
        "test = df_test.copy()"
      ],
      "metadata": {
        "id": "FIFvy50-6hk0"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Division y preprocesamiento de los datos\n",
        "\n"
      ],
      "metadata": {
        "id": "s_u4tEBGGK6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'sentimiento'\n",
        "features = 'review_es_clean'"
      ],
      "metadata": {
        "id": "D0WV-1qD6Ron"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train[features],\n",
        "                                                    train[target],\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=train[target],\n",
        "                                                    shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "8xMTT2el6WDU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Red neuronal"
      ],
      "metadata": {
        "id": "0hRVe4OJGDv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tokenizacion\n",
        "\n"
      ],
      "metadata": {
        "id": "03Omr8FCGM0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir las cr√≠ticas de texto a secuencias num√©ricas\n",
        "tokenizer = Tokenizer(num_words=20000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Ajustar el tama√±o del vocabulario en la capa Embedding\n",
        "vocab_size = min(len(word_index) + 1, 20000)\n",
        "\n",
        "# Limitar la longitud de las secuencias a un tama√±o fijo\n",
        "max_sequence_length = 200\n",
        "X_train_padded = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Convertir las etiquetas a valores num√©ricos\n",
        "labels = np.array(y_train.replace({\"negativo\": 0, \"positivo\": 1}))\n"
      ],
      "metadata": {
        "id": "yti4H_crGVB8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creacion del modelo de RNN"
      ],
      "metadata": {
        "id": "zA_AqqqNGWzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo de RNN con capas GRU\n",
        "model_opt = Sequential()\n",
        "model_opt.add(Embedding(vocab_size, 100, input_length=max_sequence_length))\n",
        "model_opt.add(GRU(64, dropout=0.2))  # Considera quitar recurrent_dropout si afecta el rendimiento en GPU\n",
        "model_opt.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Configurar el optimizador\n",
        "optimizer = optimizers.Adam()\n",
        "\n",
        "# Compilar el modelo\n",
        "model_opt.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[BinaryAccuracy(name='accuracy')])\n",
        "\n",
        "# Cantidad de √©pocas de entrenamiento\n",
        "cant_epochs = 8\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H_rKl7m_6egn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creacion de funcion para optimizar f1"
      ],
      "metadata": {
        "id": "XKXc2HnbNej3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2 * p * r / (p + r + K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)\n"
      ],
      "metadata": {
        "id": "6VUywrSVNd8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "U_vE7PtqGaFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar el modelo\n",
        "model_opt.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[f1_score])\n",
        "\n",
        "# Cantidad de √©pocas de entrenamiento\n",
        "cant_epochs = 8\n",
        "\n",
        "# Configurar el callback de Early Stopping para monitorear el f1_score\n",
        "early_stopping = EarlyStopping(monitor='val_f1_score',\n",
        "                               patience=4,\n",
        "                               mode='max',\n",
        "                               restore_best_weights=True,\n",
        "                               min_delta=0.0001)\n",
        "\n",
        "# Entrenar el modelo\n",
        "history_model_rn = model_opt.fit(X_train_padded,\n",
        "                                 labels,\n",
        "                                 epochs=cant_epochs,\n",
        "                                 batch_size=32,\n",
        "                                 validation_split=0.2,\n",
        "                                 verbose=1,\n",
        "                                 callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyKi3AF4NWPp",
        "outputId": "df360956-0b7b-4020-d1de-d4dec11290d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "875/875 [==============================] - 137s 154ms/step - loss: 0.4299 - f1_score: 0.7950 - val_loss: 0.3410 - val_f1_score: 0.8581\n",
            "Epoch 2/8\n",
            "875/875 [==============================] - 133s 152ms/step - loss: 0.2352 - f1_score: 0.9077 - val_loss: 0.3551 - val_f1_score: 0.8423\n",
            "Epoch 3/8\n",
            "875/875 [==============================] - 135s 154ms/step - loss: 0.1446 - f1_score: 0.9481 - val_loss: 0.3981 - val_f1_score: 0.8521\n",
            "Epoch 4/8\n",
            "875/875 [==============================] - 134s 153ms/step - loss: 0.0845 - f1_score: 0.9693 - val_loss: 0.4784 - val_f1_score: 0.8093\n",
            "Epoch 5/8\n",
            "875/875 [==============================] - 129s 148ms/step - loss: 0.0511 - f1_score: 0.9823 - val_loss: 0.6152 - val_f1_score: 0.8417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prediccion y muestra de la matriz"
      ],
      "metadata": {
        "id": "vAa8ZtXGGhxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Convertir las cr√≠ticas de texto de prueba a secuencias num√©ricas\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_padded = pad_sequences(sequences_test, maxlen=max_sequence_length)\n",
        "\n",
        "# Realizar predicciones\n",
        "predictions = model_opt.predict(X_test_padded)\n",
        "\n",
        "# Convertir las predicciones a etiquetas binarias\n",
        "predicted_labels = [1 if p > 0.5 else 0 for p in np.ravel(predictions)]\n",
        "\n",
        "# Convertir y_test a valores num√©ricos si es necesario\n",
        "y_test_numeric = np.array(y_test.replace({\"negativo\": 0, \"positivo\": 1}))\n",
        "\n",
        "# Calcular la matriz de confusi√≥n\n",
        "conf_matrix = confusion_matrix(y_test_numeric, predicted_labels)\n",
        "print(\"Matriz de Confusi√≥n:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqW6hg2_6m3J",
        "outputId": "7fd2d156-e449-414d-9079-d9dbf1096efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 16s 33ms/step\n",
            "Matriz de Confusi√≥n:\n",
            "[[6343 1157]\n",
            " [ 950 6550]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Guardado del modelo en H5 (similar a pickle)"
      ],
      "metadata": {
        "id": "9Cpw06g-GdDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_opt.save('red_neuronal.h5')  # Guarda el modelo en formato H5\n",
        "from google.colab import files\n",
        "files.download('red_neuronal.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "wSlzm4I1Fuj6",
        "outputId": "dd468a20-07f4-4c15-a26e-801a589102c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c78f5139-0fd0-4dd7-9edd-bb2730386007\", \"red_neuronal.h5\", 24418424)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prediccion con el dataset Test"
      ],
      "metadata": {
        "id": "9HMQr_aTGtl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Convertir las revisiones de texto a secuencias num√©ricas\n",
        "test_sequences = tokenizer.texts_to_sequences(test['review_es_clean'])\n",
        "\n",
        "\n",
        "max_sequence_length = 200\n",
        "X_test_tokenizer = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Realizar predicciones\n",
        "predictions = model_opt.predict(X_test_tokenizer)\n",
        "predicted_sentiment = ['positivo' if pred > 0.5 else 'negativo' for pred in predictions]\n",
        "\n",
        "# Agregar las predicciones al DataFrame de prueba\n",
        "test['predicted_sentiment'] = predicted_sentiment\n",
        "\n",
        "# Seleccionar solo las columnas ID y predicted_sentiment\n",
        "output = test[['ID', 'predicted_sentiment']]\n",
        "\n",
        "# Guardar las predicciones en un nuevo archivo CSV\n",
        "output.to_csv('test_predictions.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gYbEZkED5Kp",
        "outputId": "c652362b-1b79-42df-df27-74de98a3ab1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "269/269 [==============================] - 10s 36ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Descarga de la prediccion"
      ],
      "metadata": {
        "id": "3XxpkS8JG1iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar el archivo (√∫til en Jupyter Notebook o Google Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('test_predictions.csv')\n",
        "except ImportError:\n",
        "    print(\"La funci√≥n de descarga solo funciona en entornos como Google Colab.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VFMCWFStG4iw",
        "outputId": "3e772e00-c760-4c78-fcb7-065d7282c1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_23bb2480-222c-49a1-bd4e-8aac3656ce27\", \"test_predictions.csv\", 129008)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### >  Segundo modelo de Red Neuronal"
      ],
      "metadata": {
        "id": "9K-VxxsDzwUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Codificaci√≥n de las etiquetas\n",
        "label_encoder = LabelEncoder()\n",
        "train['sentimiento_encoded'] = label_encoder.fit_transform(train['sentimiento'])\n",
        "\n",
        "# Vectorizaci√≥n de las rese√±as\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(train['review_es_clean'])\n",
        "\n",
        "X = tokenizer.texts_to_sequences(train['review_es_clean'])\n",
        "X = pad_sequences(X, maxlen=200) # Ajusta este valor seg√∫n la longitud de tus rese√±as\n",
        "\n",
        "y = train['sentimiento_encoded']\n",
        "\n",
        "# Dividir en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "WeYU4WGb5dUy"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Par√°metros del modelo\n",
        "cant_clases = len(np.unique(y_train))\n",
        "d_in = X_train.shape[1]\n",
        "\n",
        "modelo_1 = keras.Sequential([\n",
        "    keras.layers.Dense(32, input_shape=(d_in,), activation='relu', kernel_initializer='uniform'), # Capa de entrada\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "\n",
        "    keras.layers.Dropout(0.6),\n",
        "\n",
        "    keras.layers.Dense(32, input_shape=(d_in,), activation='relu', kernel_initializer='uniform'),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "\n",
        "    keras.layers.Dropout(0.6),\n",
        "    keras.layers.Dense(cant_clases, activation='sigmoid') # Capa de salida\n",
        "])\n",
        "\n",
        "modelo_1.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "t8HEJqW15eHS"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = modelo_1.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUja3kKn5fDH",
        "outputId": "51431926-8d27-4956-9431-ae80a295dd28"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 6s 5ms/step - loss: 1.3807 - accuracy: 0.4990 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6950 - accuracy: 0.4985 - val_loss: 0.6927 - val_accuracy: 0.4991\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6941 - accuracy: 0.5059 - val_loss: 0.6933 - val_accuracy: 0.4891\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6934 - accuracy: 0.4982 - val_loss: 0.6932 - val_accuracy: 0.5008\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6937 - accuracy: 0.4987 - val_loss: 0.6941 - val_accuracy: 0.5058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Evaluacion y prediccion del modelo"
      ],
      "metadata": {
        "id": "fg9fBUHd9i_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluaci√≥n del modelo\n",
        "test_loss, test_acc = modelo_1.evaluate(X_test, y_test)\n",
        "\n",
        "print('Test Accuracy:', test_acc)\n",
        "\n",
        "# Realizar predicciones\n",
        "predictions = modelo_1.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k94vaMWd5q3c",
        "outputId": "12f5bea2-0cdd-4a53-a908-ab75b0283855"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4961\n",
            "Test Accuracy: 0.4961000084877014\n",
            "313/313 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Guardado del archivo con pickle"
      ],
      "metadata": {
        "id": "oZIaV0U09sUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Guardar el modelo\n",
        "with open('modelo_1.pkl', 'wb') as file:\n",
        "    pickle.dump(modelo_1, file)\n"
      ],
      "metadata": {
        "id": "waCNxgtH55Zv"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prediccion con el dataset de test"
      ],
      "metadata": {
        "id": "TADPGnMV9vP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_nuevo = tokenizer.texts_to_sequences(test['review_es_clean'])\n",
        "X_nuevo = pad_sequences(X_nuevo, maxlen=200)  # Usa la misma longitud m√°xima que antes\n"
      ],
      "metadata": {
        "id": "mg8QDzQu6x_a"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nuevas_predicciones = modelo_1.predict(X_nuevo)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGQYZRPg6Dow",
        "outputId": "b14b4005-f845-4604-b577-4cc181b275be"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "269/269 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Preparacion del csv para bajar"
      ],
      "metadata": {
        "id": "UH1FTlto91TE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Convertir las salidas del modelo en √≠ndices de clase\n",
        "indices_predicciones = np.argmax(nuevas_predicciones, axis=1)\n",
        "\n",
        "\n",
        "mapeo_etiquetas = {0: 'Negativo', 1: 'Positivo'}\n",
        "etiquetas_predicciones = [mapeo_etiquetas[i] for i in indices_predicciones]\n"
      ],
      "metadata": {
        "id": "HbDSu6xX7q64"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bajado del archivo de prediccion"
      ],
      "metadata": {
        "id": "SjjAmAPR94LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Supongamos que 'nuevo_dataset' tiene una columna 'ID'\n",
        "nuevo_dataset_predicciones = pd.DataFrame({\n",
        "    'ID': test['ID'],\n",
        "    'sentimiento': etiquetas_predicciones\n",
        "})\n",
        "\n",
        "# Guardar en un archivo CSV\n",
        "nuevo_dataset_predicciones.to_csv('predicciones_red2.csv', index=False)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('predicciones_red2.csv')\n",
        "except ImportError:\n",
        "    print(\"La funci√≥n de descarga solo funciona en entornos como Google Colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_5IF7CaM7r6z",
        "outputId": "a2ac028a-e7a6-43ec-e770-f59d6345ee8f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_18dca0db-33a6-4d10-8f63-6fa227bced12\", \"nuevas_predicciones.csv\", 129000)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}